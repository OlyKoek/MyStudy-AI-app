{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/OlyKoek/Udemy-AIperfectMaster-colabo/blob/main/lstm_rnn_transformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3x6YqwOT2gmB"
   },
   "source": [
    "# ã‚·ãƒ³ãƒ—ãƒ«ãªLSTMã¨RNNã¨Transformerã®å®Ÿè£…ã¨æ¯”è¼ƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s_o1LP7vEbu-"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, SimpleRNN, LSTM, Input, MultiHeadAttention, Add, LayerNormalization\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "niQcYtzn2gmE"
   },
   "source": [
    "## è¨“ç·´ç”¨ãƒ‡ãƒ¼ã‚¿ã®ä½œæˆ\n",
    "RNNã«ç”¨ã„ã‚‹è¨“ç·´ç”¨ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆã—ã¾ã™ã€‚  \n",
    "ã‚µã‚¤ãƒ³é–¢æ•°ã«ä¹±æ•°ã§ãƒã‚¤ã‚ºã‚’åŠ ãˆãŸãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆã—ã€éå»ã®æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰æœªæ¥ã®å€¤ã‚’äºˆæ¸¬ã§ãã‚‹ã‚ˆã†ã«ã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 470
    },
    "id": "Q90QQKUa2gmF",
    "outputId": "fa2f5e5c-2b59-4bc5-d154-629b6d8315bb"
   },
   "outputs": [],
   "source": [
    "x_data = np.linspace(-2*np.pi, 2*np.pi)\n",
    "sin_data = np.sin(x_data) + 0.1 * np.random.randn(len(x_data))\n",
    "\n",
    "plt.plot(x_data, sin_data)\n",
    "plt.title(\"Training data (sin wave with noise)\")\n",
    "plt.show()\n",
    "\n",
    "n_rnn = 10\n",
    "n_sample = len(x_data) - n_rnn\n",
    "x = np.zeros((n_sample, n_rnn))\n",
    "t = np.zeros((n_sample, n_rnn))\n",
    "\n",
    "for i in range(n_sample):\n",
    "    x[i] = sin_data[i:i+n_rnn]\n",
    "    t[i] = sin_data[i+1:i+n_rnn+1]\n",
    "\n",
    "x = x.reshape(n_sample, n_rnn, 1)\n",
    "t = t.reshape(n_sample, n_rnn, 1)\n",
    "print(\"x:\", x.shape, \"t:\", t.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rz1JVTzKEmrE"
   },
   "source": [
    "### ãƒ†ã‚¹ãƒˆç”¨ã®æ¥äºˆæ¸¬é–¢æ•°ã‚’ä½œæˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vQObxuN4EmG4"
   },
   "outputs": [],
   "source": [
    "def predict_future(model, x, n_rnn, steps=500):\n",
    "    predicted = x[0].reshape(-1)\n",
    "    for _ in range(len(x) + steps):\n",
    "        y = model.predict(predicted[-n_rnn:].reshape(1, n_rnn, 1), verbose=0)\n",
    "        predicted = np.append(predicted, y[0][-1][0])\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MqaT5_DAIjVB"
   },
   "source": [
    "## å‹¾é…ã‚’è¿½è·¡ã™ã‚‹é–¢æ•°ã‚’ä½œæˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dAaHr21hIokG"
   },
   "outputs": [],
   "source": [
    "class GradientTracker(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, model, x, y):\n",
    "        self.model = model\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.grad_norms = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        with tf.GradientTape() as tape:\n",
    "            preds = self.model(self.x, training=True)\n",
    "            loss = tf.keras.losses.mean_squared_error(self.y, preds)\n",
    "            loss = tf.reduce_mean(loss)\n",
    "        grads = tape.gradient(loss, self.model.trainable_variables)\n",
    "        total_norm = tf.linalg.global_norm(grads)\n",
    "        self.grad_norms.append(total_norm.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HpAgzbxL2gmH"
   },
   "source": [
    "## Simple RNN\n",
    "Kerasã‚’ä½¿ã£ã¦RNNã‚’æ§‹ç¯‰ã—ã¾ã™ã€‚  \n",
    "KerasãŒæŒã¤RNNã®ä¸­ã§ä¸€ç•ªã‚·ãƒ³ãƒ—ãƒ«ãªSimpleRNNå±¤ã‚’ä½¿ã„ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 222
    },
    "id": "A035R7xO2gmH",
    "outputId": "7a6ccdcc-07b4-43fd-d118-7f4a08badc98"
   },
   "outputs": [],
   "source": [
    "model_rnn = Sequential([\n",
    "    SimpleRNN(20, input_shape=(n_rnn, 1), return_sequences=True),\n",
    "    Dense(1)\n",
    "])\n",
    "print(model_rnn.summary())\n",
    "\n",
    "model_rnn.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "history_rnn = model_rnn.fit(x, t, epochs=50, batch_size=8, verbose=0, validation_split=0.1)\n",
    "pred_rnn = predict_future(model_rnn, x, n_rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "id": "Jvof_eMtKIXY",
    "outputId": "4c4c9415-3a97-4539-e3cd-a6d51bfb3b95"
   },
   "outputs": [],
   "source": [
    "model_rnn_no_clip = Sequential([\n",
    "    SimpleRNN(20, input_shape=(n_rnn, 1), return_sequences=True),\n",
    "    Dense(1)\n",
    "])\n",
    "print(model_rnn_no_clip.summary())\n",
    "\n",
    "optimizer_no_clip = keras.optimizers.SGD(learning_rate=0.5)\n",
    "model_rnn_no_clip.compile(loss=\"mse\", optimizer=optimizer_no_clip)\n",
    "\n",
    "history_no_clip = model_rnn_no_clip.fit(\n",
    "    x, t,\n",
    "    epochs=50,\n",
    "    batch_size=8,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model_rnn_clip = Sequential([\n",
    "    SimpleRNN(20, input_shape=(n_rnn, 1), return_sequences=True),\n",
    "    Dense(1)\n",
    "])\n",
    "print(model_rnn_clip.summary())\n",
    "\n",
    "optimizer_clip = optimizers.SGD(learning_rate=0.5, clipnorm=1.0)  # â†ã“ã‚Œã ã‘ã§OKï¼\n",
    "model_rnn_clip.compile(loss=\"mse\", optimizer=optimizer_clip)\n",
    "\n",
    "history_clip = model_rnn_clip.fit(\n",
    "    x, t,\n",
    "    epochs=50,\n",
    "    batch_size=8,\n",
    "    verbose=0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 410
    },
    "id": "xw44AoxtwQSH",
    "outputId": "96fa133a-e0aa-48f3-9468-4bb534bc6b17"
   },
   "outputs": [],
   "source": [
    "\n",
    "# plt.figure(figsize=(8,4))\n",
    "# plt.plot(history_no_clip.history[\"loss\"], label=\"Without Clipping\", color=\"red\")\n",
    "# plt.plot(history_clip.history[\"loss\"], label=\"With Clipping (norm=1.0)\", color=\"blue\")\n",
    "# plt.xlabel(\"Epoch\")\n",
    "# plt.ylabel(\"Training Loss (MSE)\")\n",
    "# plt.title(\"Training Stability with and without Gradient Clipping\")\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "# pred_no_clip = predict_future(model_rnn_no_clip, x, n_rnn)\n",
    "# pred_clip = predict_future(model_rnn_clip, x, n_rnn)\n",
    "\n",
    "# plt.figure(figsize=(12,6))\n",
    "# plt.plot(np.arange(len(sin_data)), sin_data, label=\"True data\", color=\"black\", linewidth=1.5)\n",
    "# plt.plot(np.arange(len(pred_no_clip)), pred_no_clip, label=\"No Clipping\", color=\"red\")\n",
    "# plt.plot(np.arange(len(pred_clip)), pred_clip, label=\"With Clipping\", color=\"blue\")\n",
    "# plt.axvline(len(sin_data), color=\"gray\", linestyle=\"--\", label=\"Prediction Start\")\n",
    "# plt.title(\"Effect of Gradient Clipping on Future Prediction (RNN)\")\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A4SImWlgEt_k"
   },
   "source": [
    "### Simple LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 222
    },
    "id": "H6Bic283ExxE",
    "outputId": "43baf480-913c-4ac6-adbe-b3d0be65910d"
   },
   "outputs": [],
   "source": [
    "model_lstm = Sequential([\n",
    "    LSTM(20, input_shape=(n_rnn, 1), return_sequences=True),\n",
    "    Dense(1)\n",
    "])\n",
    "print(model_lstm.summary())\n",
    "\n",
    "model_lstm.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "history_lstm = model_lstm.fit(x, t, epochs=50, batch_size=8, verbose=0, validation_split=0.1)\n",
    "pred_lstm = predict_future(model_lstm, x, n_rnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gwbFbSCOE_iC"
   },
   "source": [
    "### Simple Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 460
    },
    "id": "aDufQw7LFCpZ",
    "outputId": "829a018d-537f-43ab-facb-b40fba23d282"
   },
   "outputs": [],
   "source": [
    "inputs = Input(shape=(n_rnn, 1))\n",
    "x_tf = Dense(32)(inputs)  # embedding çš„å½¹å‰²\n",
    "attn_out = MultiHeadAttention(num_heads=2, key_dim=8)(x_tf, x_tf)\n",
    "x_tf = Add()([x_tf, attn_out])  # æ®‹å·®æ¥ç¶š\n",
    "x_tf = LayerNormalization()(x_tf)\n",
    "x_tf = Dense(20, activation=\"relu\")(x_tf)\n",
    "outputs = Dense(1)(x_tf)\n",
    "\n",
    "model_tf = Model(inputs, outputs)\n",
    "model_tf.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "print(model_tf.summary())\n",
    "\n",
    "model_tf = Model(inputs, outputs)\n",
    "model_tf.compile(loss=\"mse\", optimizer=\"adam\")\n",
    "history_tf = model_tf.fit(x, t, epochs=50, batch_size=8, verbose=0, validation_split=0.1)\n",
    "pred_tf = predict_future(model_tf, x, n_rnn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WU2PTTD-FHnu"
   },
   "source": [
    "## æå¤±é–¢æ•°ã®æ¯”è¼ƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "pUAlAMqtFKM_",
    "outputId": "d676c142-0444-4d37-84f8-575a8bda0fca"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(history_rnn.history[\"val_loss\"], label=\"RNN\")\n",
    "# plt.plot(history_no_clip.history[\"loss\"], label=\"Without Clipping\", color=\"red\")\n",
    "# plt.plot(history_clip.history[\"loss\"], label=\"With Clipping (norm=1.0)\")\n",
    "plt.plot(history_lstm.history[\"val_loss\"], label=\"LSTM\")\n",
    "plt.plot(history_tf.history[\"val_loss\"], label=\"Transformer\")\n",
    "plt.title(\"Validation Loss Comparison\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"MSE Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Z6eMFEsFcg0"
   },
   "source": [
    "## æ¨è«–ã«ã‚ˆã‚‹äºˆæ¸¬æ³¢å½¢ã®è¡¨ç¤º"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 545
    },
    "id": "79AmVMxfFejS",
    "outputId": "ea0341af-be11-4f24-8aa5-8c9844c23090"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(np.arange(len(sin_data)), sin_data, label=\"True data\", color=\"black\", linewidth=1.5)\n",
    "plt.plot(np.arange(len(pred_rnn)), pred_rnn, label=\"SimpleRNN\")\n",
    "plt.plot(np.arange(len(pred_lstm)), pred_lstm, label=\"LSTM\")\n",
    "plt.plot(np.arange(len(pred_tf)), pred_tf, label=\"Transformer\")\n",
    "plt.axvline(len(sin_data), color=\"gray\", linestyle=\"--\", label=\"Prediction Start\")\n",
    "plt.title(\"Future Prediction Comparison (100 steps)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SLDimRWNyhK"
   },
   "source": [
    "\"\"\"\n",
    "# ğŸ“˜ ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒã¾ã¨ã‚ï¼šSimpleRNN / LSTM / Transformer\n",
    "\n",
    "##  SimpleRNN\n",
    "### æ¦‚è¦\n",
    "- æœ€ã‚‚åŸºæœ¬çš„ãªå†å¸°å‹ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ï¼ˆRecurrent Neural Networkï¼‰\n",
    "- ç¾åœ¨ã®å…¥åŠ›ã¨ã€Œç›´å‰ã®å‡ºåŠ›çŠ¶æ…‹ã€ã‚’å†å¸°çš„ã«ä½¿ã£ã¦æ¬¡ã‚’äºˆæ¸¬\n",
    "- æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã‚’â€œé€æ¬¡çš„â€ã«å‡¦ç†ã™ã‚‹ä»•çµ„ã¿\n",
    "\n",
    "### ç‰¹å¾´\n",
    "- çŸ­ã„ä¾å­˜é–¢ä¿‚ï¼ˆç›´è¿‘ã®å‚¾å‘ï¼‰ã‚’æ‰ãˆã‚‹ã®ã¯å¾—æ„\n",
    "- é•·æœŸä¾å­˜ï¼ˆé ã„éå»ã®å½±éŸ¿ï¼‰ã‚’å­¦ç¿’ã—ã¥ã‚‰ã„ï¼ˆå‹¾é…æ¶ˆå¤±å•é¡Œï¼‰\n",
    "- ãƒ¢ãƒ‡ãƒ«æ§‹é€ ãŒå˜ç´”ã§å­¦ç¿’ãŒé€Ÿã„ãŒã€æ³¢å½¢ãŒé•·æœŸçš„ã«ãšã‚Œã‚‹å‚¾å‘\n",
    "\n",
    "### æœ¬å®Ÿé¨“ã§ã®æŒ™å‹•\n",
    "- ãƒã‚¤ã‚ºã‚’å«ã‚“ã sinæ³¢ã®çŸ­å‘¨æœŸã¯ã†ã¾ãè¿½å¾“\n",
    "- ãŸã ã—ã€å‘¨æœŸãŒç¶šãã»ã©æ³¢å½¢ãŒå¾ã€…ã«å¹³æ»‘åŒ–ãƒ»æ¸›è¡°ã™ã‚‹ã‚‰ã—ã„\n",
    "- å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ãŒçŸ­ã„å ´åˆï¼ˆ1ã€œ2å‘¨æœŸï¼‰ã§ã¯å®‰å®šã ãŒé•·æœŸäºˆæ¸¬ã«å¼±ã„\n",
    "\n",
    "---\n",
    "\n",
    "##  LSTMï¼ˆLong Short-Term Memoryï¼‰\n",
    "### æ¦‚è¦\n",
    "- RNNã®å‹¾é…æ¶ˆå¤±ã‚’é˜²ããŸã‚ã«ç”Ÿã¾ã‚ŒãŸæ”¹è‰¯ãƒ¢ãƒ‡ãƒ«\n",
    "- ã€Œã‚»ãƒ«çŠ¶æ…‹ã€ã‚’å†…éƒ¨ã«æŒã¡ã€é‡è¦æƒ…å ±ã‚’ä¿æŒãƒ»ä¸è¦æƒ…å ±ã‚’å¿˜å´\n",
    "- å…¥åŠ›ãƒ»å‡ºåŠ›ãƒ»å¿˜å´ã‚²ãƒ¼ãƒˆã®3æ©Ÿæ§‹ã§æƒ…å ±ã‚’åˆ¶å¾¡\n",
    "\n",
    "### ç‰¹å¾´\n",
    "- é•·æœŸä¾å­˜ã®å­¦ç¿’ãŒå¯èƒ½ï¼ˆå‘¨æœŸãƒ»ãƒˆãƒ¬ãƒ³ãƒ‰ã®å†ç¾åŠ›ãŒé«˜ã„ï¼‰\n",
    "- å‡ºåŠ›ã®æ»‘ã‚‰ã‹ã•ã‚„å‘¨æœŸå†ç¾æ€§ãŒRNNã‚ˆã‚Šã‚‚å®‰å®š\n",
    "- ãŸã ã—ã€ãƒ‡ãƒ¼ã‚¿ãŒå°‘ãªã„ã¨æŒ¯å¹…ï¼ˆä¸Šä¸‹ã®ã‚¹ã‚±ãƒ¼ãƒ«ï¼‰ãŒéå­¦ç¿’çš„ã«åºƒãŒã‚‹ã“ã¨ãŒã‚ã‚‹\n",
    "\n",
    "### æœ¬å®Ÿé¨“ã§ã®æŒ™å‹•\n",
    "- å‘¨æœŸï¼ˆæ³¢ã®é•·ã•ï¼‰ã¯RNNã‚ˆã‚Šæ˜ç¢ºã«å†ç¾\n",
    "- ãŸã ã—ã€æŒ¯å¹…ï¼ˆç¸¦æ–¹å‘ã®ã‚¹ã‚±ãƒ¼ãƒ«ï¼‰ãŒã‚„ã‚„å¤§ãããªã‚‹\n",
    "- å°‘é‡ãƒ‡ãƒ¼ã‚¿ï¼‹Adamæœ€é©åŒ–ã«ã‚ˆã‚‹éé©å¿œå‚¾å‘ãŒè¦‹ã‚‰ã‚Œã‚‹\n",
    "- å¯¾ç­–ã¨ã—ã¦ã¯æ­£å‰‡åŒ–ã‚„ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µã€RMSPropãªã©ã®æœ€é©åŒ–ãŒæœ‰åŠ¹\n",
    "\n",
    "---\n",
    "\n",
    "##  Transformer\n",
    "### æ¦‚è¦\n",
    "- RNNã‚„LSTMã®ã‚ˆã†ãªã€Œå†å¸°æ§‹é€ ã€ã‚’æŒãŸãªã„æ–°ã—ã„ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£\n",
    "- Attentionæ©Ÿæ§‹ã«ã‚ˆã‚Šã€Œéå»ã®å…¨å…¥åŠ›ã€ã‹ã‚‰é–¢é€£åº¦ã‚’å‹•çš„ã«è¨ˆç®—\n",
    "- ä½ç½®æƒ…å ±ï¼ˆPositional Encodingï¼‰ã‚’ä¸ãˆã‚‹ã“ã¨ã§æ™‚ç³»åˆ—é †åºã‚’ç†è§£\n",
    "\n",
    "### ç‰¹å¾´\n",
    "- é•·æœŸä¾å­˜ãƒ»è¤‡é›‘ãªæ™‚ç³»åˆ—ãƒ»éå‘¨æœŸãƒ‡ãƒ¼ã‚¿ã®å­¦ç¿’ã«éå¸¸ã«å¼·ã„\n",
    "- ä¸¦åˆ—è¨ˆç®—ãŒå¯èƒ½ã§å­¦ç¿’åŠ¹ç‡ãŒé«˜ã„\n",
    "- å°‘é‡ãƒ‡ãƒ¼ã‚¿ã§ã¯å¹³å‡åŒ–å‚¾å‘ãŒå¼·ãã€å¹³å¦ãªäºˆæ¸¬ï¼ˆç›´ç·šï¼‰ã«ãªã‚ŠãŒã¡\n",
    "\n",
    "### æœ¬å®Ÿé¨“ã§ã®æŒ™å‹•\n",
    "- æå¤±é–¢æ•°ï¼ˆMSEï¼‰ã¯æœ€ã‚‚å°ã•ã„ â†’ å¹³å‡çš„ã«â€œå®‰å…¨ãªå‡ºåŠ›â€ã‚’é¸æŠã—ã¦ã„ã‚‹\n",
    "- ã—ã‹ã—æ³¢å½¢ã®è¿½å¾“æ€§ã¯ä½ãã€å‘¨æœŸæ€§ã‚’å†ç¾ã§ããªã„\n",
    "- åŸå› ã¯ã€Œä½ç½®æƒ…å ±ã®æ¬ å¦‚ã€ã¨ã€Œãƒ‡ãƒ¼ã‚¿é‡ä¸è¶³ã€\n",
    "- Positional Encodingã‚’å°å…¥ã™ã‚‹ã¨å‘¨æœŸæ€§ãŒéƒ¨åˆ†çš„ã«å¾©æ´»\n",
    "\n",
    "---\n",
    "\n",
    "## ç·è©•ï¼ˆä»Šå›ã®sinæ³¢ã‚¿ã‚¹ã‚¯ï¼‰\n",
    "\n",
    "| è¦³ç‚¹ | SimpleRNN | LSTM | Transformer |\n",
    "|------|------------|------|--------------|\n",
    "| æ³¢å½¢ã®è¿½å¾“æ€§ | â—¯ | â— | â–³ |\n",
    "| é•·æœŸäºˆæ¸¬ã®å®‰å®šæ€§ | â–³ | â— | â—¯ï¼ˆä½ç½®æƒ…å ±æ¬¡ç¬¬ï¼‰ |\n",
    "| æå¤±å€¤ï¼ˆMSEï¼‰ | ä¸­ | ä½ | æœ€ä½ï¼ˆãŸã ã—å¹³å¦åŒ–å‚¾å‘ï¼‰ |\n",
    "| è¨ˆç®—é€Ÿåº¦ | â—ï¼ˆæœ€é€Ÿï¼‰ | â—¯ | â–³ï¼ˆAttentionè¨ˆç®—ã‚ã‚Šï¼‰ |\n",
    "| å°‘é‡ãƒ‡ãƒ¼ã‚¿é©æ€§ | â— | â—¯ | Ã— |\n",
    "| æ‹¡å¼µä½™åœ° | ä½ | ä¸­ | é«˜ï¼ˆæ”¹è‰¯æ¬¡ç¬¬ã§æœ€å¼·ï¼‰ |\n",
    "\n",
    "---\n",
    "\n",
    "## ã¾ã¨ã‚\n",
    "- **SimpleRNN**ï¼šæ™‚ç³»åˆ—å­¦ç¿’ã®åŸç‚¹ã€‚æ§‹é€ ã¯å˜ç´”ã§ç†è§£ã«æœ€é©ã€‚\n",
    "- **LSTM**ï¼šå®Ÿå‹™ãƒ¬ãƒ™ãƒ«ã§æœ€ã‚‚å®‰å®šã€‚å‘¨æœŸã‚„ãƒˆãƒ¬ãƒ³ãƒ‰å†ç¾ã«å¼·ã„ã€‚\n",
    "- **Transformer**ï¼šAttentionã®å¨åŠ›ã§ã€Œéå»å…¨ä½“ã€ã‚’è¦‹æ¸¡ã›ã‚‹ãŒã€  \n",
    "ã€€ä½ç½®æƒ…å ±ã¨ååˆ†ãªå­¦ç¿’ãƒ‡ãƒ¼ã‚¿ãŒãªã‘ã‚Œã°æ³¢å½¢å†ç¾ã¯å›°é›£ã€‚  \n",
    "ã€€æ™‚ç³»åˆ—ã‚¿ã‚¹ã‚¯ã§ã¯Positional Encodingã®å°å…¥ãŒå¿…é ˆã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1Y9aiNx2OWDz"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
